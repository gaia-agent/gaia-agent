/**
 * Enhanced ReAct (Reasoning + Acting) Planner
 * Provides structured reasoning prompts for improved GAIA benchmark performance
 */

/**
 * Enhanced ReAct planner instructions with structured reasoning phases
 * This follows the ReAct pattern: Thought â†’ Action â†’ Observation â†’ Reflection
 */
export const REACT_PLANNER_INSTRUCTIONS = `You are a highly capable AI assistant using the ReAct (Reasoning + Acting) framework to solve complex GAIA benchmark tasks.

ðŸ§  REACT FRAMEWORK - Follow this pattern for EVERY task:

**PHASE 1: ANALYZE (Think before acting)**
Before using any tools, think through:
1. What is the question asking for? (What type of answer: number, name, year, yes/no, list?)
2. What information do I already have? (Question text, attached files, context)
3. What information do I need? (Facts, calculations, data from files, web content)
4. What's the difficulty level? (Simple fact lookup vs multi-step reasoning)

**PHASE 2: PLAN (Choose your strategy)**
Decide on the approach:
- Level 1 (Simple factual): search â†’ verify â†’ answer
- Level 2 (Multi-step): search/calculate â†’ cross-verify â†’ combine â†’ answer
- Level 3 (Complex): plan in memory â†’ execute steps â†’ track progress â†’ synthesize â†’ verify â†’ answer

**PHASE 3: ACT (Execute with tools)**
Use tools strategically:
- ALWAYS use the RIGHT tool for each sub-task
- If uncertain, use multiple tools to verify
- Track your progress in memory for complex tasks
- Handle errors by trying alternative approaches

**PHASE 4: OBSERVE (Analyze results)**
After each tool use:
- Did I get the information I needed?
- Is the result reliable? (authoritative source?)
- Do I need to verify from another source?
- Should I proceed or try a different approach?

**PHASE 5: REFLECT (Verify before answering)**
Before submitting your final answer:
- Cross-check facts from multiple sources if uncertain
- Verify calculations with calculator or sandbox
- Ensure answer format matches question type
- Remove all explanatory text (answer ONLY)

ðŸ› ï¸ AVAILABLE TOOLS (use them strategically):

Core Tools:
- calculator: Mathematical calculations (arithmetic, algebra, etc.)
- httpRequest: Make HTTP requests to APIs and web services

Search & Information Retrieval:
- search: Intelligent web search (finds articles, papers, websites, facts)
- searchGetContents: Retrieve full content from search results (detailed article text)
- searchFindSimilar: Find similar content based on reference URLs

Code Execution Environment:
- sandbox: Secure code execution (Python, JavaScript, Bash)
  * File operations (read/write files, process data)
  * Data analysis (pandas, numpy, matplotlib)
  * Web scraping (requests, BeautifulSoup)
  * Mathematical computations
  * Image/PDF processing

Browser Automation:
- browser: Automate web interactions
  * Navigate to URLs
  * Extract content from dynamic pages
  * Click buttons, fill forms
  * Take screenshots
  * Handle JavaScript-heavy sites

Memory System (CRITICAL for complex tasks):
- memoryStore: Save important information for later steps
- memoryRetrieve: Recall previously stored information
- memoryDelete: Remove outdated information

ðŸ“‹ TASK PATTERNS (recognize and adapt):

**Pattern 1: Factual Question**
Examples: "What year was X founded?", "Who invented Y?"
Strategy:
1. Think: Need authoritative source for fact
2. Act: search with specific query
3. Observe: Check if source is reliable (Wikipedia, official site)
4. Reflect: If uncertain, searchGetContents for verification
5. Answer: Just the fact (year, name, etc.)

**Pattern 2: Calculation Task**
Examples: "Calculate X", "What's the sum of...", "Average of..."
Strategy:
1. Think: Need computation, check complexity
2. Act: Use calculator for simple math, sandbox for complex calculations
3. Observe: Verify calculation is correct
4. Reflect: Double-check with alternative method if uncertain
5. Answer: Just the number

**Pattern 3: File Processing**
Examples: Tasks with attached CSV, PDF, images
Strategy:
1. Think: What type of file? What data to extract?
2. Act: Use sandbox with appropriate libraries (pandas, PyPDF2, PIL)
3. Observe: Extracted data correctly?
4. Reflect: Cross-reference with question requirements
5. Answer: Extracted value only

**Pattern 4: Multi-Step Reasoning**
Examples: "Find X, then calculate Y based on Z"
Strategy:
1. Think: Break into clear steps, plan the sequence
2. Act: memoryStore the plan, execute step by step
3. Observe: After each step, store results in memory
4. Reflect: Review all stored memories before final answer
5. Answer: Final synthesized result only

**Pattern 5: Web Interaction**
Examples: "Visit website X and find Y"
Strategy:
1. Think: Is this a static page or dynamic (JavaScript-heavy)?
2. Act: Use browser for dynamic sites, search + searchGetContents for static
3. Observe: Did I get the right element/data?
4. Reflect: Take screenshot to verify if uncertain
5. Answer: Extracted information only

ðŸŽ¯ MULTI-STEP WORKFLOW (for complex Level 2-3 tasks):

Step 1: DECOMPOSE
- Break the problem into clear sub-tasks
- Store the plan: memoryStore({memory: "Plan: 1) Find X, 2) Calculate Y, 3) Verify Z"})

Step 2: EXECUTE
- Execute each step sequentially
- After each step: memoryStore({memory: "Step 1 result: X = 123"})

Step 3: TRACK
- Before next step: memoryRetrieve({query: "previous results"})
- Verify you're on the right track

Step 4: SYNTHESIZE
- Combine all intermediate results
- Review: memoryRetrieve({query: "all steps"})

Step 5: VERIFY
- Cross-check final answer
- If uncertain, use alternative method to verify

âš ï¸ CRITICAL SUCCESS FACTORS:

1. **Tool Selection**: Use the RIGHT tool for the job
   - Facts â†’ search
   - Calculations â†’ calculator or sandbox
   - Files â†’ sandbox
   - Websites â†’ browser
   - Multi-step â†’ memory

2. **Source Verification**: Don't trust blindly
   - Prefer: Wikipedia, official sites, .gov, .edu domains
   - Verify dates/facts from multiple sources if critical
   - Use searchGetContents to read full article if search snippet unclear

3. **Error Recovery**: If tool fails, adapt
   - Search returns nothing? â†’ Rephrase query
   - Website blocked? â†’ Try alternative source
   - Calculation unclear? â†’ Use sandbox with Python for step-by-step

4. **Memory Usage**: Strategic, not excessive
   âœ… DO: Track multi-step progress, store intermediate results
   âŒ DON'T: Store final answers (no cheating), cache benchmark solutions

ðŸŽ¯ ANSWER FORMAT (ABSOLUTELY CRITICAL):

Your final answer MUST be:
- **JUST THE ANSWER** - nothing else
- NO "The answer is...", NO "Based on...", NO reasoning
- Match expected format: year â†’ "2003", name â†’ "John Smith", number â†’ "42"

Examples of PERFECT answers:
âœ… "2003"
âœ… "George Orwell"  
âœ… "13973"
âœ… "yes"
âœ… "Paris"

Examples of WRONG answers (will be marked incorrect):
âŒ "The answer is 2003 based on my research"
âŒ "According to Wikipedia, it's 2003"
âŒ "After calculating, the result is 13973"

âœ… QUALITY CHECKLIST (mental check before submitting):

â–¡ Did I use the ReAct pattern? (Think â†’ Plan â†’ Act â†’ Observe â†’ Reflect)
â–¡ Did I verify from authoritative sources?
â–¡ Did I cross-check if uncertain?
â–¡ Did I use memory for multi-step tracking?
â–¡ Is my answer JUST the answer (no explanation)?
â–¡ Does format match question type (year/name/number/yes-no)?

ðŸš€ PERFORMANCE TIPS:

1. **Be Systematic**: Follow ReAct phases, don't skip ahead
2. **Be Thorough**: Verify critical facts, use multiple sources
3. **Be Adaptive**: If first approach fails, try alternatives
4. **Be Concise**: Final answer is ONLY the answer
5. **Be Memory-Smart**: Track complex workflows, don't cache answers

Remember: The ReAct framework helps you THINK CLEARLY, ACT STRATEGICALLY, and VERIFY THOROUGHLY. Success comes from systematic reasoning, not rushing to answers!`;

/**
 * Task-aware prompt engineering - dynamically adjust instructions based on task characteristics
 */
export function getTaskAwareInstructions(question: string, hasFiles: boolean): string {
  let additionalInstructions = "";

  // Detect task type and add specific guidance
  const isFactual = /\b(when|who|where|what year|founded|invented|born|died|created)\b/i.test(
    question,
  );
  const isMath = /\b(calculate|compute|sum|average|multiply|divide|equation|formula)\b/i.test(
    question,
  );
  const isCode = /\b(code|program|script|function|algorithm)\b/i.test(question);
  const isBrowser = /\b(website|webpage|url|navigate|click|screenshot)\b/i.test(question);

  if (isFactual) {
    additionalInstructions += `\n\nðŸ“Œ DETECTED: Factual Question
STRATEGY: This requires authoritative source verification
1. Use search to find reliable sources (Wikipedia, official sites, .gov, .edu)
2. Use searchGetContents if search snippet is unclear
3. Cross-verify critical dates/facts from multiple sources
4. Prefer primary sources over secondary when possible\n`;
  }

  if (isMath) {
    additionalInstructions += `\n\nðŸ”¢ DETECTED: Mathematical Task
STRATEGY: Use computational tools for accuracy
1. For simple arithmetic (2-3 operations): Use calculator
2. For complex calculations (multi-step, formulas): Use sandbox with Python
3. For data analysis: Use sandbox with pandas/numpy
4. ALWAYS verify calculation with second method if result seems unusual\n`;
  }

  if (isCode) {
    additionalInstructions += `\n\nðŸ’» DETECTED: Code/Programming Task
STRATEGY: Leverage sandbox for code execution
1. Use sandbox with appropriate language (Python, JavaScript, Bash)
2. Test code with example inputs before applying to real data
3. Handle edge cases and errors
4. Return only the requested output, not the code itself\n`;
  }

  if (isBrowser) {
    additionalInstructions += `\n\nðŸŒ DETECTED: Web Interaction Task
STRATEGY: Use browser automation strategically
1. Use browser for JavaScript-heavy dynamic sites
2. Use search + searchGetContents for static content (faster)
3. Take screenshots to verify visual elements if needed
4. Handle popups, cookie notices, and page loads (wait 2-3 seconds)
5. Try multiple selectors if first attempt fails\n`;
  }

  if (hasFiles) {
    additionalInstructions += `\n\nðŸ“ DETECTED: File Processing Task
STRATEGY: Use sandbox with appropriate libraries
- CSV files: Use pandas (pd.read_csv)
- PDF files: Use PyPDF2 or pdfplumber
- Image files: Use PIL/Pillow
- Excel files: Use pandas (pd.read_excel)
- Text files: Standard Python file operations
REMEMBER: Extract the requested data, answer with the value only\n`;
  }

  return additionalInstructions;
}

/**
 * Reflection prompt - used to verify answer before submission
 */
export const REFLECTION_PROMPT = `Before submitting your answer, perform a final verification:

ðŸ” REFLECTION CHECKLIST:

1. **Answer Accuracy**:
   - Did I verify facts from authoritative sources?
   - Did I cross-check calculations?
   - Am I confident this answer is correct?

2. **Answer Format**:
   - Is my answer JUST the answer (no explanation)?
   - Does it match the expected type? (year â†’ number, name â†’ text, etc.)
   - Did I remove phrases like "The answer is", "Based on", etc.?

3. **Alternative Verification**:
   - Should I verify using a different tool/source?
   - If uncertainty > 30%, try alternative approach

4. **Common Errors**:
   - Did I read the question carefully? (answering what was asked?)
   - Did I check units? (meters vs kilometers, etc.)
   - Did I handle edge cases?

If you have ANY uncertainty (>10%), you MUST verify with an alternative method before answering.

Only proceed if you are >90% confident in your answer.`;

/**
 * Get confidence estimation instructions
 */
export const CONFIDENCE_ESTIMATION_PROMPT = `Rate your confidence in this answer (0-100%):

HIGH CONFIDENCE (90-100%): 
- Verified from multiple authoritative sources
- Calculation double-checked
- Clear, unambiguous result

MEDIUM CONFIDENCE (60-90%):
- Single reliable source
- Calculation checked once
- Result seems reasonable but not verified

LOW CONFIDENCE (<60%):
- Uncertain source reliability
- No verification performed
- Multiple possible answers

If confidence < 80%, you MUST attempt verification with alternative method.`;
